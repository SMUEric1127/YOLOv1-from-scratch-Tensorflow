{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_IMAGES = 200\n",
    "TRAIN_IMAGES = 2000\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "GRID_SIZE = 5\n",
    "BOX_SIZE = 1 #originally 2 boxes -> choose the one with the highest iou => we will not do in here\n",
    "NUM_CLASS = 2\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesNum = {'dog': 0, 'cat': 1}\n",
    "def convertFunction(folder, name, file):\n",
    "    path = folder + '/' + name\n",
    "    path = os.path.normpath(path)\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    file.write(path.replace('xml', 'png'))\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        className = obj.find('name').text\n",
    "        if className not in classesNum.keys() or int(difficult) == 1:\n",
    "            continue\n",
    "\n",
    "        #get bounding box\n",
    "        box = ( int(obj.find('bndbox').find('xmin').text),\n",
    "                int(obj.find('bndbox').find('ymin').text),\n",
    "                int(obj.find('bndbox').find('xmax').text),\n",
    "                int(obj.find('bndbox').find('ymax').text))\n",
    "\n",
    "        id = list(classesNum.keys()).index(className)\n",
    "\n",
    "        #write to file\n",
    "        file.write(' ' + ','.join([str(a) for a in box]) + ',' + str(id))\n",
    "    file.write('\\n')\n",
    "\n",
    "with open(os.path.join('%s.txt' % ('annotations')) , 'w') as f:\n",
    "    for file in os.listdir('annotations'):\n",
    "        if file.endswith('.xml'):\n",
    "            convertFunction(folder = 'annotations', name=str(file), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = []\n",
    "with open(os.path.normpath('annotations.txt'), 'r') as f:\n",
    "    train_datasets = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datasets = train_datasets[:VALIDATION_IMAGES]\n",
    "train_datasets = train_datasets[VALIDATION_IMAGES : VALIDATION_IMAGES + TRAIN_IMAGES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images:  2000 Val images:  200\n"
     ]
    }
   ],
   "source": [
    "print('Train images: ', len(train_datasets), 'Val images: ', len(val_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotationConverting(dataset):\n",
    "    X, Y = [], []\n",
    "    for item in dataset:\n",
    "        item = item.replace(\"\\n\", \"\").split(\" \")\n",
    "        X.append(item[0])\n",
    "        arr = []\n",
    "        for i in range(1, len(item)):\n",
    "            arr.append(item[i])\n",
    "        Y.append(arr)\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = annotationConverting(train_datasets)\n",
    "X_val, Y_val = annotationConverting(val_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, images, labels, shuffle=False):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.images) / int(BATCH_SIZE))).astype(int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.images[idx * BATCH_SIZE : (idx + 1) * BATCH_SIZE] # images path\n",
    "        batch_y = self.labels[idx * BATCH_SIZE : (idx + 1) * BATCH_SIZE] # raw label\n",
    "\n",
    "        train_image, train_label = [], []\n",
    "        for i in range(0, len(batch_x)):\n",
    "            img_path, label = batch_x[i], batch_y[i]\n",
    "            image, label_matrix = self.read(img_path, label) #actual image array (IMAGE_SIZE, IMAGE_SIZE, 3) (GRID_SIZE, GRID_SIZE, 5 * BOX_SIZE + CLASS) \n",
    "            train_image.append(image)\n",
    "            train_label.append(label_matrix)\n",
    "        \n",
    "        if self.shuffle:\n",
    "            indices = tf.range(start=0, limit=tf.shape(train_image)[0], dtype=tf.int32)\n",
    "            idx = tf.random.shuffle(indices)\n",
    "            train_image = tf.gather(train_image, idx)\n",
    "            train_label = tf.gather(train_label, idx)\n",
    "\n",
    "        return np.array(train_image, dtype=np.float32), np.array(train_label, dtype=np.float32)\n",
    "    \n",
    "    def read(self, img_path, label):\n",
    "        image = cv.imread(img_path)\n",
    "        h, w = image.shape[0:2]\n",
    "        image = cv.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        image = image / 255.\n",
    "\n",
    "        label_matrix = np.zeros([GRID_SIZE, GRID_SIZE, 5 * BOX_SIZE + NUM_CLASS])\n",
    "        for l in label:\n",
    "            l = l.split(',')\n",
    "            l = np.array(l, dtype=int)\n",
    "\n",
    "            xmin, ymin, xmax, ymax = l[0] / w, l[1] / h, l[2] / w, l[3] / h # [0, 1]\n",
    "            \n",
    "            x, y = (xmin + xmax) / 2, (ymin + ymax) / 2\n",
    "            w, h = xmax - xmin, ymax - ymin\n",
    "\n",
    "            #convert x, y relative to the cell\n",
    "            i, j = int(GRID_SIZE * y), int(GRID_SIZE * x)\n",
    "            x = GRID_SIZE * x - j # 7 * [0,1] = [0, 7] e.g: 6.43 - int(6.43) = 0.43 => relative to the cell\n",
    "            y = GRID_SIZE * y - i\n",
    "\n",
    "            if l[4] == 0:\n",
    "                label_matrix[i, j] = [x, y, w, h, 1, 1, 0]\n",
    "            if l[4] == 1:\n",
    "                label_matrix[i, j] = [x, y, w, h, 1, 0, 1]\n",
    "        return image, label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataGenerator = DataGenerator(X_train, Y_train)\n",
    "validationDataGenerator = DataGenerator(X_val, Y_val)\n",
    "\n",
    "x_train, y_train = trainingDataGenerator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'cat']\n"
     ]
    }
   ],
   "source": [
    "classArray = list(classesNum.keys())\n",
    "print(classArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestPrint(image, label):\n",
    "    for i in range(GRID_SIZE):\n",
    "        for j in range(GRID_SIZE):\n",
    "            if label[i][j][4] > 0.5:\n",
    "                print(label[i][j])\n",
    "                x, y, w, h = label[i][j][:4]\n",
    "\n",
    "                xmax = int(((x + j) / GRID_SIZE * IMAGE_SIZE) + (w * IMAGE_SIZE) / 2)\n",
    "                xmin = int(((x + j) / GRID_SIZE * IMAGE_SIZE) - (w * IMAGE_SIZE) / 2)\n",
    "                ymax = int(((y + i) / GRID_SIZE * IMAGE_SIZE) + (h * IMAGE_SIZE) / 2)\n",
    "                ymin = int(((y + i) / GRID_SIZE * IMAGE_SIZE) - (h * IMAGE_SIZE) / 2)\n",
    "\n",
    "                className = classArray[tf.argmax(label[i][j][5:], axis=-1)]\n",
    "                cv.putText(image, className, (xmin, ymax + 10), cv.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 255, 255))\n",
    "                cv.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 255, 255), 1)\n",
    "    #image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    cv.imshow('Visualize', image)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyWindow('Visualize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = trainingDataGenerator.__getitem__(0)\n",
    "idx = 6\n",
    "TestPrint(x_train[idx], y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloActivation(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        classes = tf.nn.softmax(inputs[..., 5:], axis=-1)\n",
    "        coordinates = tf.sigmoid(inputs[..., :5])\n",
    "        return tf.concat([coordinates, classes], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n",
      "82420632/82420632 [==============================] - 4s 0us/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 7, 7, 1280)        20331360  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 3, 1280)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3, 3, 1280)       5120      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 11520)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              11797504  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 175)               89775     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 5, 5, 7)           0         \n",
      "                                                                 \n",
      " yolo_activation (YoloActiva  (None, 5, 5, 7)          0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,750,607\n",
      "Trainable params: 12,415,663\n",
      "Non-trainable params: 20,334,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, MaxPool2D, BatchNormalization\n",
    "\n",
    "lrelu = tf.keras.layers.LeakyReLU(alpha=0.1)\n",
    "\n",
    "featureExtractor = Sequential()\n",
    "featureExtractor.add(tf.keras.applications.efficientnet_v2.EfficientNetV2M(\n",
    "    include_top = False,\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "))\n",
    "\n",
    "featureExtractor.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(featureExtractor)\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation=lrelu))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation=lrelu))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(GRID_SIZE * GRID_SIZE * (BOX_SIZE * 5 + NUM_CLASS))) #total nodes we need -> reshape them into the grid (GRID_SIZE, GRID_SIZE, BOX_SIZE * 5 + NUM_CLASS)\n",
    "model.add(Reshape((GRID_SIZE, GRID_SIZE, BOX_SIZE * 5 + NUM_CLASS))) # linear activation function (-inf, inf) -> takes longer to converge and not that good\n",
    "model.add(YoloActivation()) #convert last two class probability into a softmax outputs\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO LOSS !!!\n",
    "def yoloLoss(y_true, y_pred):\n",
    "    coordLoss = CoordLoss(y_true, y_pred)\n",
    "    confidenceLoss = ConfidenceLoss(y_true, y_pred)\n",
    "    classLoss = ClassLoss(y_true, y_pred)\n",
    "\n",
    "    return 25 * coordLoss + 15 * confidenceLoss + 5 * classLoss\n",
    "\n",
    "def CoordLoss(y_true, y_pred):\n",
    "    #find if it exist an object in the grid\n",
    "    existsObject = tf.expand_dims(y_true[..., 4], -1)\n",
    "\n",
    "    xy_pred = existsObject * y_pred[..., 0:2]\n",
    "    xy_true = existsObject * y_true[..., 0:2]\n",
    "\n",
    "    wh_pred = existsObject * tf.math.sign(y_pred[..., 2:4]) * tf.sqrt(tf.math.abs(y_pred[..., 2:4])) #if it's linear (-inf, inf)\n",
    "    wh_true = existsObject * tf.sqrt(y_true[..., 2:4])\n",
    "\n",
    "    coordLoss = tf.reduce_sum(tf.math.square(wh_pred - wh_true))\n",
    "    coordLoss += tf.reduce_sum(tf.math.square(xy_pred - xy_true))\n",
    "\n",
    "    return coordLoss / tf.cast(tf.math.count_nonzero(existsObject), dtype=tf.float32) #mean, but it's fine if we don't\n",
    "\n",
    "def ConfidenceLoss(y_true, y_pred):\n",
    "    existsObject = tf.expand_dims(y_true[..., 4], -1)\n",
    "\n",
    "    confidenceLoss = tf.reduce_sum(tf.math.square(existsObject * (y_true[..., 4:5] - y_pred[..., 4:5])))\n",
    "    confidenceLoss += 0.5*tf.reduce_sum(tf.math.square((1 - existsObject) * (y_true[..., 4:5] - y_pred[..., 4:5])))\n",
    "\n",
    "    return confidenceLoss / tf.cast(tf.math.count_nonzero(existsObject), dtype=tf.float32) #mean, but it's fine if we don't\n",
    "\n",
    "def ClassLoss(y_true, y_pred):\n",
    "    existsObject = tf.expand_dims(y_true[..., 4], -1)\n",
    "\n",
    "    classLoss = tf.reduce_sum(tf.math.square(existsObject * (y_true[..., 5:] - y_pred[..., 5:])))\n",
    "    return classLoss / tf.cast(tf.math.count_nonzero(existsObject), dtype=tf.float32) #mean, but it's fine if we don't\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = yoloLoss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=[CoordLoss, ConfidenceLoss, ClassLoss]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    }
   ],
   "source": [
    "model.fit(  x = trainingDataGenerator,\n",
    "            validation_data = (validationDataGenerator),\n",
    "            epochs = 300,\n",
    "            workers = 8,\n",
    "            validation_freq = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "[0.2942742  0.5018323  0.4791737  0.58642685 0.99996674 0.99850523\n",
      " 0.00149476]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[3.0476224e-01 8.3730859e-01 1.5449563e-01 1.4743602e-01 9.9920017e-01\n",
      " 9.9975306e-01 2.4693698e-04]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "[7.8192466e-01 5.7377201e-01 2.8494388e-01 3.1162944e-01 9.9926645e-01\n",
      " 9.9996006e-01 3.9913368e-05]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[1.9740531e-01 1.2624970e-01 3.1917673e-01 3.8819090e-01 9.9303764e-01\n",
      " 8.3120285e-05 9.9991691e-01]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "[0.5699612  0.20659435 0.33492556 0.34023908 0.99761957 0.9951994\n",
      " 0.00480065]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "[0.44433254 0.57880026 0.326442   0.3963741  0.9999447  0.0014199\n",
      " 0.9985801 ]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[8.8392013e-01 7.8798074e-01 3.4697822e-01 6.4350444e-01 9.9999905e-01\n",
      " 9.9965823e-01 3.4172251e-04]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "[0.69665325 0.68278134 0.25451207 0.32668868 0.99982506 0.99679095\n",
      " 0.00320906]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "[0.6652639  0.60251343 0.35951394 0.35398906 0.9999087  0.99763346\n",
      " 0.00236652]\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    image = cv.imread('annotations/Cats_Test20' + str(i) + '.png')\n",
    "    image = cv.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = image / 255.\n",
    "    TestPrint(image, model.predict(np.expand_dims(image, 0))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: yolov1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: yolov1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('yolov1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5aa9f2987bed8a3ec25348c0d4744ce9188797e2d4a4a0ad2f33eef625f8243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
